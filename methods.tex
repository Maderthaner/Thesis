\chapter{Methods}\label{ch:methods}
This chapter describes the analysis methods used in the present thesis and it is organized as follows: Section \ref{sec:LCLS-computing} describes the general LCLS computing environment to establish an overview of the hard- and software capabilities; Section \ref{sec:pnccd-corr} discusses common corrections and the combination of raw pnCCD images;  Section \ref{sec:phase-retrieval} goes over used phase-retrieval algorithms and discusses the image resolution; Section \ref{sec:pump--probe-considerations} considers the contribution of scattering from the X-ray pump--X-ray probe pulses; Section \ref{sec:2d-simulations} discusses simulations of 2D projections of spheres and corresponding diffraction patterns; and the Section \ref{sec:hitfinding} evaluates several hit-finding methods.
%
%
%
\section{The computing environment at LCLS}\label{sec:LCLS-computing}
%%%%%%%%%%%%%%%%
%- Include basics around the PSANA interface\\
%- For example how the date is converted, then stored and\\
%- the analysis opportunities along the way
%- I think this will be a longer subsection since a lot of my work went into this and I'm regularly contacted about it.
%- Short introduction what we have to go through\\
%- Reminder of detectors and analysis environment
%%%%%%%%%%%%%%%%
\begin{figure}
	\centering
		\includegraphics[width=1.00\textwidth]{images/daq-architecture.JPG}
	\caption[Diagram of the computing environment at LCLS and DAQ traffic.]{Diagram of the computing environment at LCLS and DAQ traffic. The recorded data is exchanged through Ethernet and after digitization, is stored on a cache and FFB cluster, where psana computer have access to the online environment during the experiment. Eventually, the data is moved to the more permanent offline environment, where data can be analyzed on psana computers or through a load sharing facility. Adapted from \citep{Amadeo-2016-SLAC}.}
	\label{fig:daq-architecture}
\end{figure}
All data taken at LCLS are stored in the LCLS computing environment, where the data can also be analyzed. The reason for this is the vast amount of data that are generated by LCLS and the instruments. Let us conservatively estimate the data produced by the LAMP end-station. Usually, the LAMP end-station has two pnCCD detectors that operate at a \SI{120}{\hertz} frame rate. Each image is in a 32 bit-per-pixel format such that an image is approximately \SI{4}{\mega\byte} in size. So, every minute the front \& rear pnCCD produce approximately \SI{60}{\giga\byte} of data or \SI{700}{\giga\byte} per \SI{12}{\hour} shift. The handling of these data is indicated in Figure \ref{fig:daq-architecture}. The DAQ readout nodes send the data traffic via Ethernet to a short-term cache and fast feedback (FFB) layer. While the data are being transferred, online monitoring nodes are able to ``see'' a fraction of the live (online) data and run analysis. With a delay of a few tens of seconds, the FFB nodes can be used to run analysis on the full data stream using parallelization. The FFB nodes can only be used during the beamtime. Eventually, the data are moved to normal hard-drives (offline), where the data files are managed by an integrated Rule-Oriented Data System (iRODS). The data are stored in .XTC file containers and it can also be accessed from outside SLAC (Router \& ESNET). The stored data have certain storage quotas and times. In brief, there is a six month short-term storage without quota limitations and a two-year medium-term storage with a storage quota of \SI{10}{\tera\byte}. After that, the data are automatically stored for at least ten years on magnetic tape (long-term storage) and can be restored upon request. A web interface is provided by the DAQ group to simplify and automate the data-handling and logging process. The short- and medium-term storage solutions can also be used to analyze the data using the Psana\footnote{Psana is an acronym for Photon Science Analysis.} software package \citep{Damiani-2016-JSR} to access data and to perform computations on the psana computer cluster with over 1000 CPU cores. A load sharing facility (LSF) allows the scheduling of batch jobs including parallelization. The psana-framework has a python script interface. The python script calls functions within the psana-framework that are programmed in C(++), for example, detector calibrations. Psana allows parallelization via Message Passing Interface (MPI) and it is therefore possible to analyze many events (LCLS pulses) simultaneously. Also complex analysis is able to be processed at the rate of the incoming data using MPI, when the FFB is used. Python scripts can be written for ``online'' or ``offline'' analysis and are of similar syntax.\\[1\baselineskip]
%
For LCLS-II \citep{Amadeo-2016-SLAC}, the analysis and data-access scheme is designed to be similar to Figure \ref{fig:daq-architecture} with the exception of the online monitoring nodes. It is therefore recommended to build analysis schemes that are based on psana and use the FFB for online analysis, which can then be adapted easily for offline analysis as well. A quick introduction on how to use psana can be found at \url{https://confluence.slac.stanford.edu/display/PSDM/LCLS+Data+Analysis} (from February 2017).
%
%
%
\section{pnCCD photon detectors}\label{sec:pnccd-corr}
%%%%%%%%%%%%%%%%
%- Describe signal on the pnCCDs\\
%- Calibrations and corrections - use LAMP paper\\
%- single hits\\
%- multiple hits
%%%%%%%%%%%%%%%%
\begin{figure}
	\centering
		\includegraphics[height=0.45\textwidth]{images/pnCCD-electronic-noise.png}
	\caption[ADU histograms from electronic noise of dark pnCCDs.]{ADU histograms from electronic noise of dark pnCCDs in highest gain mode. The green plus symbols reflect a histogram of ADU values from raw electronic noise of pnCCD pixel. The noise is set off zero at $\mu_{r}=1515$ ADU and has a standard deviation $\sigma_{r}=136$ ADU. The same data shifts to the blue stars after applying a pedestal subtraction and the noise distribution has $\mu_{p}=-3$ ADU and $\sigma_{p}=109$ ADU. For the red data points, the common-mode corrections have been applied and the distribution has $\mu_{c}=0$ ADU and $\sigma_{c}=17$ ADU.}
	\label{fig:pnCCD-electronic-noise}
\end{figure}
Before the pnCCD detectors can be used to take data, it is good practice to record dark reference images. These reference images allow software corrections to the raw detector image in order to reduce detector artifacts, such as electronic noise. Since these corrections are standard, the LCLS detector and DAQ group has implemented a calibration manager tool\index{psana!calibman}\footnote{The calibration manager tool calibman can be found in the psana software package. More information under \url{https://confluence.slac.stanford.edu/display/PSDM/Calibration+Management+Tool} (Oct 2016)} (calibman) that provides the necessary algorithms and helps with the procedure of applying image corrections and more. We discuss the two most-often used software corrections next. The first, corrects for the electronic noise pedestals\index{pnCCD!pedestal correction} (levels) of each pixel, and, the second, accounts for common modes\index{pnCCD!common mode}, e.g., artifacts from the read-out electronics that appear, for the pnCCD, mostly in columns.\\[1\baselineskip]
%
The effects of applying these corrections are illustrated in Figure \ref{fig:pnCCD-electronic-noise} through a set of histograms. The histogram bins are showing ADU values from dark pnCCD images in highest gain. The green curve shows the ADU values of a raw detector image where no corrections have been applied and the electronic noise response from the chip has a standard deviation of $\sigma_{r}=136$ ADU. Note, that there is also a significant offset of the distribution from 0 ADU to $\mu_{r}=1515$ ADU. The blue curve shows the same data but is using the pedestal corrections found in calibman. The pedestal corrections reduce the noise slightly to $\sigma_{p}=109$ ADU, and as expected, the pedestal corrections drastically move the normal distribution to be centered around $\mu_{p}=-3$ ADU. Finally, the red curve is also the same data than the green curve but includes pedestal and common-mode corrections. The corrected read-out modes drastically improve the standard deviation to $\sigma_{c}=17$ ADU and slightly move the mean to $\mu_{c}=0$ ADU.\\[1\baselineskip]
%
As a guideline, the pedestal corrections should always be used to account for the mean offset. The common-mode calibration, however, should be tested before applying. The algorithm that determines common-modes needs to find a baseline and therefore needs at least one pixel with no signal in each row and column \citep{Hantke-Foucard-2016-PC}. In single-particle imaging experiments, the detector is usually illuminated in most pixel. In this case, the common-mode correction algorithm may treat real signal as noise and fail to find a common baseline.\\[1\baselineskip]
%
In the present thesis, pedestal and common-mode correction has always been applied on the front detectors, as only few pixel hold signal. The rear pnCCD uses the pedestal correction but corrects common-modes only above a certain, conservative threshold. See Figure \ref{fig:pnCCD-image-aligned} for the visible effect on front detector (large, top/bottom arrays) and rear detector (small, centered array).\\
%
%
%
%\subsection{Signal analysis}
%- Present data from 1500eV photon energy on Xe backfilled chamber with the pnCCDs in spectroscopy mode to argue that the pedestal and offset corrections are enough to correct for fluoresence.\\
%- Masked areas in image
%%%
%
%
%
\subsection{Combining multiple pnCCD detectors}\label{sec:combination-of-images}
%%%%%%%%%%%%%%%%%%%%%%%%%
%- Explain how I combined pnCCD detectors to perform reconstructions on it.\\
%- Can reuse material from the LAMP pnCCD paper
%%%%%%%%%%%%%%%%%%%%%%%%%
In order to maximize resolution, it is most useful to combine the front and rear pnCCD detector images from a single-shot into one larger image. While this is a simple task in itself, it becomes more complex when the combined images need to undergo a phase-retrieval process that use fast Fourier transformations (FFTs). In fact, it has not yet been shown in single-particle imaging that it is possible to retrieve a real space image from multiple detectors in different planes.
%One of the reasons is, that the samples, that were studied in recent years were comparably large, e.g. viral samples of a few hundred nanometer radius that don't scatter to wide angles. Therefore, in many experimental setups, the distance of this detector is then set to fill the detector planes appropriately to the scattering of the sample. In other words, there was no incentive of combining detectors.
The reason for this is that, so far, there was little incentive for merging multiple detectors. The combination of light-source, end-station, and sample size (compare, e.g., Reference \cite{Seibert-2011-Nature}) means that little signal is detected at large scattering angles. With the intensities provided by LCLS and the single-particle imaging capabilities of the LAMP end-station, objects that are smaller than a hundred nanometer in diameter can be studied. This setup scatters significant signal at larger scattering angles that multiple pnCCD detector planes can be used.
%To cover this variety in object size, LAMP's front pnCCD detector can move along the z-axis and can cover wide scattering angles from smaller objects and LAMP's rear pnCCD detector covers the usual small angles scattering from larger objects. Once the detector is set to cover most scattering angles, one finds that the dynamic range and photon sensitivity becomes a limiting element.
The combination of front and rear pnCCD detector images has three advantages: one, covering larger scattering angles increases the resolution; two, multiple detectors can be operated in different gains, which virtually increases the dynamic range of the combined system; and three, the signal-to-noise of the combined system is improved.\\[1\baselineskip]
%
Let us now describe the process of combining multiple detector images from a single-shot, while simultaneously preparing them for the inverse problem of phase-retrieval. This basically requires two steps: one, the intensity normalization for the detectors that are in different gains and positions; and two, the pixel projection and down-sampling, which is here from the rear pnCCD plane to the front pnCCD plane. The discussion below follows the code shown in Appendix \ref{sec:combination-of-detectors-code}. The input for the following procedure are two pnCCD images. The images should be pedestal corrected and, if applicable, common-mode corrected (see Section \ref{sec:pnccd-corr}). Analysis of the electronic noise results in a cutoff or offset between signal-to-noise for each image (see Figure \ref{fig:pnCCD-histogram}a and \ref{fig:pnCCD-electronic-noise}). At this step it is also convenient to account for different detector gain settings, gain$_{\text{front,rear}}$, using Table \ref{tab:gain-modes} and the detector distances from the interaction region, distance$_{\text{front,rear}}$, to equalize the measured intensities. The following equation corrects the signal from the rear pnCCD to the front pnCCD plane
\begin{equation}
I(\text{pixel}_{X},\text{pixel}_{Y})_{\text{normalized}} = I(\text{pixel}_{X},\text{pixel}_{Y})\cdot \frac{\text{gain}_{\text{front}}}{\text{gain}_{\text{rear}}} \cdot \frac{\text{distance}_{\text{rear}}^{2}}{\text{distance}_{\text{front}}^{2}},
\end{equation}
pixel$_{X}$ and pixel$_{Y}$ being the length of the pixel array from the beam along the X- and Y-axis, respectively. The pnCCD front top and bottom module are placed in an enlarged array to reflect the real geometry in the plane of the front pnCCD. We can now transform the rear pnCCD data to this pixel-constructed geometry. Let us use the earlier introduced scattering angle, $\Theta$, in $X$- and $Y$-axis separately
\begin{equation}
\Theta_{X,Y} = \arctan\left(\frac{\text{pixel}_{X,Y} \cdot a}{\text{distance}_{\text{rear}}}\right),
\label{eqn:scattering-angle}
\end{equation}
where $a$ is the pixel size along one dimension. We can further generalize the matter and attribute a scattering vector $\vec{Q}$ to each pixel, with the entries in $X$- and $Y$-axis separately again
\begin{equation}
Q_{X,Y} = 4 \pi \frac{\sin\left(\frac{\Theta_{X,Y}}{2}\right)}{\lambda},
\label{eqn:q-vector}
\end{equation}
with $\lambda$ being the wavelength of the scattered photons. Now, we can add the signal from the rear pnCCD to the enlarged array, while using the generalized coordinates $\vec{Q}$. In this generalized downsampling process, the arithmetic mean of the downsampled pixel is used, which is why a normalization factor needs to be carried. The downsampling of the rear pnCCD and placement in the enlarged array ensures the new pixel size matches the one from the front pnCCD. This allows Fast Fourier Transformation (FFT) algorithms to use the array. The usage of FFT algorithms is of great interest to reduce computing times in iterative phase-retrieval algorithms.\\[1\baselineskip]
%
%
%
\begin{figure}
	\centering
		\includegraphics[width=0.8\textwidth]{images/pnCCD-image-geometry2.png}
	\caption[Front and rear pnCCD arranged to combine measured diffraction image.]{A combined pnCCD image using the full image of the front pnCCD and a down-sampled image of the rear pnCCD. The red circles in the image are drawn to visualize the alignment of the detectors. As described in the text, the intensities in the image are normalized and corrected for different electronic gains and distance to specific detectors. The black areas are not covered by the pnCCDs and are therefore masked out.}
	\label{fig:pnCCD-image-aligned}
\end{figure}
%
An example of a combined diffraction image from a spherical xenon cluster of \SI{\sim 50}{\nano\meter} radius is shown in Figure \ref{fig:pnCCD-image-aligned}. The front pnCCD detector was set to slightly overlap with the rear pnCCD detector along the $Y$-axis, but the front detector was set \SI{\sim 365}{\milli\meter} closer to the interaction region along the $Z$-axis. As described above, the rear pnCCD modules have been projected into the front pnCCD plane and in this process, the detector appears smaller on the combined image. The red circles are a help for the eye to align the modules and show that the diffraction pattern overlaps. In this exemplary data, the front pnCCD was operated in highest gain $\frac{1}{1}$ and the rear pnCCD was operated in lowest gain $\frac{1}{256}$.\\[1\baselineskip]
\begin{figure}
	\centering
		\includegraphics[height=0.50\textwidth]{images/pnCCD-1d-sum.png}
	\caption[Spherical projection of 2D diffraction image onto 1D.]{Spherical projection of 2D diffraction image onto 1D. The data points are from the rear pnCCD (green points) and the front pnCCD (blue points) have been combined. The gray shaded area shows the transition area from rear to front detector. The red curve is a simulated scattering curve from an ideal sphere (see Equation \eqref{eq:scattering from sphere}). The amplitude of the red curve has been fitted to the data points and it agrees well with the data.}
	\label{fig:pnCCD-1d-sum}
\end{figure}
A good way of checking the continuity of the merged data is through the radial intensity profiles of the diffraction images (see Section \ref{sec:1d-proj-and-phase-reconstruction}). Figure \ref{fig:pnCCD-1d-sum} shows the radial intensity profile of the spherically symmetric diffraction image over 5 orders of magnitude above the noise level. The red curve illustrates the expected scattering intensity of a spherical object using Equation \eqref{eq:scattered-intensity} and \eqref{eq:scattering from sphere}. The red curve showcases the validity of the detected signal up to the edges of the front pnCCD, where little signal is present. There are also some discrepancies from the red curve on the transition from the rear to front pnCCD, which are due to the shadow projected from the front onto the rear pnCCD and the resulting lack of signal. 
%As indicated in the Section \ref{sec:saxs}, Equations \eqref{eq:scattered-intensity} and \eqref{eq:scattering from sphere} can be exploited to automatically determine the radius, $r$, of the cluster and the incident beam intensity, $I_{0}$ by automatically fitting the red curve to the data points. This is 
%
%
%
\section{Phase retrieval from a single diffraction pattern}\label{sec:phase-retrieval}
%%%%%%%%%%%%%%
%- Short intro into phase retrieval
%%%%%%%%%%%%%%
The diffractive imaging measures the continuous intensity distribution of an object in reciprocal space and the phase information is lost (see Section \ref{sec:saxs}). Iterative algorithms can retrieve this lost information because there are only limited sets of phases that uniquely reproduce the diffraction image \citep{Bruck-1979-OpticsCom,Bates-1981-Optik}. To fully recover the original function, i.e., real and complex values of the imaged object, the diffraction image must be oversampled\index{oversampling} \citep{Sayre-1952-ActCryst}. Here, the \textit{Nyquist-Shannon sampling theorem}\index{oversampling!Nyquist-Shannon sampling theorem} says that a Fourier transformed object, $A(\vec{Q})$, of size $X$ can be fully recovered if its sampling rate is at least at the Nyquist rate\index{oversampling!Nyquist rate} of $\tfrac{1}{2X}$ -- with an \textit{oversampling} of two. Since, we measure the intensity distribution, $I(\vec{Q})$, and not the scattered amplitude distribution, $A(\vec{Q})$, this rate must be adapted to $\tfrac{1}{4X}$. The Nyquist rate can be translated into a minimum pixel-size in real-space that samples $I(\vec{Q})$ using the following relation between a discrete Fourier transformation and pixel length along one dimension, $\Delta_{r}$ \citep{Williams-2010-NJP}. We note
\begin{equation}
\Delta_{r} \leq \frac{\lambda L}{4 X},
\label{eq:disc-fourier-relation-pixelsize}
\end{equation}
with the wavelength $\lambda$, the length from the interaction region to the detector $L$, and the object length along one dimension $X$. This means that larger objects require a more frequent sampling of the scattered intensity distribution. If a large, micrometer-sized object is imaged under typical experimental parameters, where $\lambda =$ \SI{1.5}{\nano\meter}, $L = \SI{0.371}{\meter}$, and $X=\SI{100}{\nano\meter}$, the detector pixel-size must be $\Delta_{r} \leq \SI{1.39}{\milli\meter}$ along each pixel dimension to fully recover the particle's projected electron density. In the present experiment, the pnCCD pixel-area of \SI{75 x 75}{\micro\meter} samples also the largest measured objects sufficiently.
%
%
%
\subsection{Principle of phase retrieval}\label{sec:phase-retrieval-fundamental}
%%%%%%%%%%%%%%
%- Introduce some aspects from phase retrieval algorithms.
%%%%%%%%%%%%%%
\begin{figure}
	\centering
		\includegraphics[width=0.80\textwidth]{images/phase-retrieval-algorithm.png}
	\caption[Example of a phase retrieval algorithm.]{Principle of a phase retrieval algorithm. The real space object $g_{k}\left(x\right)$ is Fourier transformed to $G_{k}\left(q\right)$. The function $G_{k}\left(q\right)$ is altered to fit the constraints set in Fourier space and becomes $G'_{k}\left(q\right)$. $G'_{k}\left(q\right)$ is inverse Fourier transformed to $g'_{k}\left(x\right)$. After fulfilling the real space constraints the iterative starts again using $g_{k+1}\left(x\right)$. After \citep{Fienup-1982-AO}.}
	\label{fig:phase-retrieval-algorithm}
\end{figure}
To recover the phase from an oversampled diffraction pattern and thus reconstruct an image of the object, iterative algorithms have been developed \cite{Fienup-1982-AO}. Figure \ref{fig:phase-retrieval-algorithm} illustrates such an iterative algorithm, where the image of an object $g_{k}\left(x\right)$ is Fourier transformed to reciprocal space $G_{k}\left(q\right)$ and then inverse transformed again resulting in $g_{k+1}(x)$, while sufficing certain constraints.\\[1\baselineskip]
%
The constraints are rather strictly defined in the reciprocal space as they have to reproduce the actual measurement $I=A\cdot A^{*}$, which is sometimes called the modulo constraint. The criteria that need to be met in real space can be chosen more freely. Generally, the recovered object should be physical, i.e., should be of a certain (known) size. One can introduce a support structure $S$ that meets the physical constraints and can therefore be used to, for example, zero outlying values. Throughout the iterations, the functions $g_{k}(x)$ evolve and eventually converge into a solution. If one uses the above criterion, one can show that the error between the reconstructions and the actual measurement continuously reduces, which is why it is commonly referred to as error-reduction algorithm \cite{Fienup-1978-OL}.
%
%
%
%
%\subsection{Solving the inverse problem}
\subsection{2D reconstructions and image resolution}
%
%
%
\subsubsection{Hawk program for 2D image phase retrieval}
%%%%%%%%%%%%%%%%%
%- Describe Filipe's program
%%%%%%%%%%%%%%%%%
For all image reconstructions in 2D, the Hawk software package\index{Hawk software package} \citep{Maia-2010-JAC} has been used. Hawk is available under the GNU General Public License\footnote{Hawk copyright: \url{https://github.com/FXIhub/hawk/blob/master/Copyright}} and can be downloaded with installation instructions from \url{https://github.com/FXIhub/hawk}. In previous efforts to retrieve a real-space image from FEL based coherent diffractive imaging, Hawk has been used successfully in several reconstructions ranging from viruses \citep{Seibert-2011-Nature,Ekeberg-2015-PRL} to other few-hundred-nanometer-sized objects \citep{Seibert-2010-JPhysB} but has not yet been used to recover the real space image from rare-gas cluster.
\begin{table}%[h!]
\centering
\begin{tabular}{ |c|c|}
 \hline
 \textbf{Parameter} & \textbf{Setting} \\ 
 %a & b & c & d & e \\
 %[0.5ex] 
 \hline
 Starting Guess & random phases \\ \hline
 Autocorrelation Selection & threshold \\ \hline
 Autocorrelaton Threshold & 0.04  \\ \hline
 Phasing method beta & 0.9  \\ \hline
 Beta range & 0 - $\infty$ \\ \hline
 Enforce positivity & false   \\ \hline
 Enforce real & false     \\\hline
Perturb weak reflections & false \\ \hline
Phasing algorithm & raar \\ \hline
Blur & 12 - 0.7 \\ \hline
Blur range & 0 - 12000 \\ \hline
Center image & false \\ \hline
Object area & 0.0022 - 0.0019 \\ \hline
Object area range & 0-8000\\ \hline
Support update algorithm & area \\ \hline
\end{tabular}
\caption[Typical parameters used in the Hawk software package.]{Typical parameters used in the Hawk software package. The object area depends strongly on the actual particle size and thus varies.}
\label{tab:hawk-parameter}
\end{table}
The usage of the program is straight-forward in three steps. First, the diffraction images are transformed into the ``.cxi'' format, which uses HDF5 as base and adopts a variety of other rules to have a uniform format for SPI data-files \citep{Maia-2012-NatMet}. Second, diffraction images are prepared in \textit{Hawk's editor}, where particular effort has to be made to create a pixel mask. The mask prevents shadowed or otherwise faulty pixels from introducing unphysical signals into the reconstruction algorithm. The software suite automatically interpolates between masked pixel regimes, which is acceptable over the length of a few pixels in one direction. Third, \textit{Hawk's phaser} can be used to iteratively retrieve the phase from the ``.cxi'' intensity file. Typical parameters for the program can be found in Table \ref{tab:hawk-parameter}. These parameters are found iteratively and typically require running the phase retrieval of one object various times. This also results in significant demands to the computing environment and it is highly recommended to run the calculations based on a graphics processing unit (GPU), thus making use of Hawk's Nvidia CUDA® support\footnote{Nvidia is a company that designs GPUs and provides software that interfaces with their chips, such as ``CUDA'', which is a parallel computing platform.}. Therefore, it is worth emphasizing that the \textit{RAAR algorithm} \cite{Luke-2005-IP} in combination with initially strong \textit{blurs}, the extension of the \textit{phasing beta range}, and a proper determination of the \textit{object area} resulted in useful reconstructions of clusters using Hawk. Note, that the object area size differs from particle to particle and is a sensitive parameter. After \num[fixed-exponent=0]{\sim 15000} iterations, the real space object typically converges.
%
%
%
\subsubsection{Resolution enhancement through combination of rear and front pnCCD}\label{sec:resolution-discussion}
%%%%%%%%%%%%%%%
%- Showcase difference of rear pnCCD only vs. front + rear pnCCD vs. front + rear pnCCD 'cropped' for best results. Recycle work from LAMP pnCCD paper
%%%%%%%%%%%%%%%
\begin{figure}
  \begin{center}
   \includegraphics[width=1\linewidth]{images/Phase-retrieval-image.png}\\
   \includegraphics[height=3.5cm]{images/Phase-retrieval-error.png}
    \caption[Illustration of resolution enhancement and diffraction image cropping.]{Illustration of resolution enhancement due to detector combination. The diffraction pattern in Figure \ref{fig:pnCCD-image-aligned} of a Xe-cluster has been reconstructed to illustrate several cases. Top left: Rear pnCCD data only reconstruction yields a non-spherical object; error criterion shows no convergence (see graph). Top middle: Front \& rear pnCCD data results in a spherical object but missing areas next to the rear pnCCD disturb the reconstruction process, such that the electron density becomes unphysical. Top right: A cropped diffraction image without the missing areas next to rear pnCCD enables a physical reconstruction.}
\label{fig:phase-retrieval-image}
  \end{center}
\end{figure}
While there is no complete consensus on how to define resolution in a coherent diffractive imaging pattern and the resulting reconstruction, there are various good estimates \cite{Geilhufe-2014-OptcsExp,Ekeberg-2015-PRL,Chapman-2006-JOSA}. A simple and conservative method to define resolution in a diffraction pattern is Abbe's criterion, which comes from microscopy and calculates the minimal resolvable feature size in a diffraction pattern. The fundamental limit that the minimal resolvable feature size is dependent on the wavelength has also given us the inspiration to build short-wavelength machines such as the free electron laser and new synchrotron light sources.\\[1\baselineskip]
%
For Abbe's criterion, we must first verify that we are in the far field by fulfilling the following requirement \cite{Williams-2010-NJP}
\begin{equation}
\frac{X^{2}}{\lambda L} \ll 1
\label{eq:far-field-test}
\end{equation}
with the wavelength of the X-rays $\lambda$, the distance to the detector $L$, and the object size $X$. In this work, the criterion is met.\\[1\baselineskip]
%
In the far field, Abbe's criterion can be written down as
% Internal note, Max did check that we are in the far field.
\begin{equation}
    d_r = \frac{\lambda}{2n \sin(\frac{\Theta}{2})},
		\label{eq:abbe-criterion}
\end{equation}
with the minimal resolvable feature size $d_r$, the refractive index $n$ and the half scattering angle $\frac{\Theta}{2}$. The scattering angle is restricted by either the active detector area, which goes back to the typical understanding of a numerical aperture, or the signal intensity up to certain angles. The latter is in interplay with the photon wavelength and object scattering cross-sections.\\[1\baselineskip]
%This interplay leads to the current assessment that very high energy photons, e.g., $8$ keV photons that are commonly used for crystallographic purposes, scatter too little signal. Additionally, low-$\vec{Q}$ scattering is often unresolvable due to straylight. As current results indicate, using $0.5-5$ keV photons ultimately lead to higher resolution images than using $8$ keV photons \citep{Aquila-2015-StrucDyn}.\\
In the far field, we can use the following relation to determine the actual size of a pixel, $\Delta_{s}$, in a recovered real space image of an object. We note \cite{Williams-2010-NJP}
\begin{equation}
    \Delta_{s} = \frac{\lambda L}{N \Delta_{d}},
\label{eq:relation-pixel-fourier}
\end{equation}
with $L$ being the length from the interaction region to the detector, $\Delta_{d}$ being the linear detector pixel size, and $N$ being the side length of the discrete detector array.\\[1\baselineskip]
%
Figure \ref{fig:phase-retrieval-image} top shows several reconstructions of a xenon cluster at $\lambda = 1$ nm using different portions of the diffraction pattern in Figure \ref{fig:pnCCD-image-aligned}. If just the rear pnCCD is used for reconstructions, a maximum scattering angle of $\Theta\approx 4.2$° is recorded, which results in a minimal resolvable feature size of $d_{r}\approx 14$ nm. However, in the present data a shadow from the front detector is cast on the rear detector. This reduces the maximum scattering angle in the image \textbf{Rear pnCCD} that can be found in the top left panel of Figure \ref{fig:phase-retrieval-image} to $\Theta\approx 3.8$° and thus the resolution to $d_{r}\approx 15$ nm. The pixel size is \SI{\sim 10 x \sim 12}{\nano\meter}. The image \textbf{Combined pnCCDs} of Figure \ref{fig:phase-retrieval-image} uses the whole data including the empty areas next to the rear pnCCD. The image shows an unphysical electron density distribution, which originates from the empty areas next to the rear pnCCD data. In these areas, which have been masked out, the interpolation along the $Y$-axis and the extrapolation along the $X$-axis fails. The next image labeled \textbf{Cropped pnCCDs} in Figure \ref{fig:phase-retrieval-image} uses data in its full extent along the $Y$-axis but is cropped along the $X$-axis such that the blank areas are excluded. The reconstruction converges into an object that appears physical. The maximum scattering angle here is $\Theta \approx 9.2$° and the resolution thus $d_{r}\approx \SI{6}{\nano\meter}$. The pixel-size here is \SI{\sim 10 x \sim 3}{\nano\meter}.\\[1\baselineskip]
%
This is a factor \num{\sim 5} improvement over common cited studies in single particle imaging \citep{Seibert-2011-Nature} and still a factor \num{\sim 3} better than \citep{Hantke-2014-NatPho}, where measured diffraction patterns have been ``computationally purified''. The resolution enhancement due to the combination of detectors can be exploited further using expand-maximze-compress (EMC) algorithms \citep{Loh-2009-PRE}. EMC algorithms arrange multiple diffraction patterns according to their orientation and are thus able to compute averaged 3D diffraction patterns of a few hundred diffraction images of identical objects. When conducting an experiment in the LAMP end-station, the missing areas next to the rear pnCCDs could be populated in such an averaged diffraction image since the object is imaged at random orientations. Ultimately, this allows 3D reconstructions of nanoparticles with nanometer resolution\footnote{Depending on the position of the front pnCCD.}.\\
%
%
%
\subsection{1D projections and phase reconstructions}\label{sec:1d-proj-and-phase-reconstruction}
%%%%%%%%%%%%%%%%
%- Describe my algorithm in 1D in detail
%%%%%%%%%%%%%%%%
The main goal of reconstructions in this thesis is to recover an image of the object while it undergoes the nanoplasma formation and expansion. The effects of the nanoplasma evolution on the spherically symmetric cluster can be considered isotropic \citep{Gorkhover-2016-NatPho}. It is thus useful to display diffraction patterns and projected electron densities in one dimension to simplify the comparison of the transient states. A 1D representation of the data allows furthermore the comparison to analytical models. To reduce the 2D diffraction data to 1D the program shown in Appendix \ref{sec:spherical-integration} has been employed. It is based on \textsc{Matlab}\index{Matlab}, which efficiently iterates through pixel arrays. The input for this program are pedestal-calibrated diffraction images that have a true image center defined. Key elements of the algorithm are: iterating through every pixel, filtering signal from noise, disregarding missing areas, determining the scattering angle of every pixel, and adding signal over $\lvert \vec{Q}\rvert$, while normalizing the data over the pixel number. To recover the object in real space, an algorithm has been designed to perform phase retrieval on the 1D data.
%This program is based on python and can also be found in appendix \ref{sec:1d-phase-retrieval-code}. The input for this algorithm are mirrored, zero-frequency (inverse) shifted 1D diffraction arrays.
The algorithm follows the fundamental scheme described in Section \ref{sec:phase-retrieval-fundamental} and is shown in Appendix \ref{sec:1d-phase-retrieval-code}. Thereby, the real space data of the object is forced to be real and positive, which is also the error criterion in real space. The difference to the measured data yields the error criterion in Fourier space. The algorithm allows monitoring of the Fourier and real space error, the phase and the actual Fourier and real space images. The iterative algorithm is aborted when the error criterion meets a predetermined threshold.
%
%
%
\section{Impact of the X-ray pump--X-ray probe on diffraction pattern}\label{sec:pump--probe-considerations}
\begin{figure}
	\centering
		\includegraphics[width=0.49\textwidth]{images/electron-density-convoluted-object.png}
		\includegraphics[width=0.49\textwidth]{images/beam-convoluted-with-object.eps}
	\caption[Influence of X-ray pump--X-ray probe pulses to a diffraction image.]{Electron density of spheres that show surface softening (left) and resulting scattering patterns (right). In the right panel, the red line is the scattering of an intact sphere, the brown line is the scattering of an expanding sphere with $k=$ \SI{5}{\nano\meter}, and the blue line shows the combined scattering of an intact and expanding sphere that has been pumped with \SI{10}{\percent} and probed with \SI{90}{\percent} of the overall pulse energy.}
	\label{fig:electron-density-convoluted-object}
\end{figure}
For the X-ray pump--X-ray probe diffractive imaging experiment of this thesis, both pulses contribute to the scattering image. But, in this thesis experiment, only the diffraction image from the probe-pulse is interesting. This is why the pump-pulse was set to \SI{\sim 10}{\percent} of the overall pulse energy, and therefore, the pump-pulse did not contribute significantly to the diffraction image. However, in order to simulate the effects of the pump-pulse to the diffraction image, a 1D simulation is conducted using electron densities of spheres, $\rho\left(R\right)$. At our present resolution the cluster can be well-simulated using spheres (see Section \ref{sec:saxs}). To simulate the radiation damage that is induced by the pump-pulse, the spheres are allowed to undergo a surface softening. Mathematically, this can be described as an exponential decay according to the model \cite{Gorkhover-2016-NatPho}
\begin{align}
\rho\left(R, k\right)&=\begin{cases}
1 & \text{for $r-k \geq R \geq 0$},\\
e^{\frac{(r-k)-R}{k}}&\text{for $r > R - k$},
\end{cases}
\intertext{where $r$ is the cluster radius, $R$ is the distance from the center of the cluster, and $k$ an expansion parameter such that}
\int_{0}^{\infty}\rho\left(R, k\right)dR &= r,\quad \text{if } 0<k<r 
\label{eq:el-density-expanding}
\end{align}
The electron density can then be Fourier transformed into reciprocal space using the transformation in 1D due to the symmetry. With the spatial frequencies, Q, we may note \citep{Guinier-1955-JWS}
\begin{equation}
I\left(Q\right)=I_{0}F^{2}(Q)=I_{0} \left(\int_{0}^{\infty}\rho\left(R,k\right)\frac{\sin\left(Q R\right)}{Q R}4 \pi R^{2}dR\right)^{2},
\label{eq:guinier-fourier-transform}
\end{equation}
where an incident beam has the intensity $I_{0}$. This 1D simulation enables us to simulate electron densities of intact and expanding clusters and we can Fourier transform these electron densities into reciprocal space to compare it to measured diffraction images. The left panel of Figure \ref{fig:electron-density-convoluted-object} shows the electron densities for $r=\SI{50}{\nano\meter}$ and $k=$ \SIlist{0;2.5;5;10}{\nano\meter}. The right panel of Figure \ref{fig:electron-density-convoluted-object} showcases corresponding cases of expanding spheres in reciprocal space. The red line is the scattering of a solid sphere, $F_{\text{intact}}^{2}$, with $r=$ \SI{50}{\nano\meter} and $k=$ \SI{0}{\nano\meter}. The brown curve is the scattering of an expanding sphere, $F_{\text{expanding}}^{2}$, with $r=$ \SI{50}{\nano\meter} and $k=$ \SI{5}{\nano\meter}. Lastly, the blue curve is comparable to the case of this experiment. Here, the electron densities of an intact and expanding sphere were Fourier transformed and multiplied with the incident beam intensities corresponding to the pump- and probe-pulse. So, \SI{10}{\percent} of the overall intensity, $I_{0}$, is in the pump-pulse and \SI{90}{\percent} is in the probe-pulse. The transformation in reciprocal space thus reads, $I_0 F^{2}\rightarrow \SI{10}{\percent}\cdot I_0 F_{\text{intact}}^{2}+ \SI{90}{\percent}\cdot I_0 F_{\text{expanding}}^{2}$. Here, the pump-pulse affects the diffraction pattern at high $Q$-values and decreases the fringe contrast. However, the added signal from the pump-pulse remains within the noise level of $I\left(Q\right)<1$ ADU. For this assessment, the simulated incident beam intensities, $I_0$, and cluster radius, $r$, have been fitted to match the experimental data of Figure \ref{fig:pnCCD-1d-sum}.
%
%
%
\section{2D electron density and diffraction image simulations}\label{sec:2d-simulations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Describe 2D simulations
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
	\centering
		a)\includegraphics[width=0.45\textwidth]{images/cluster-generation-2D.jpg}
		b)\includegraphics[width=0.45\textwidth]{images/cluster-generation-1D.png}
	\caption[Used electron densities in 2D real and Fourier space simulations.]{a) Electron density of a $R\approx \SI{100}{\nano\meter}$ expanding sphere with $k=\SI{5}{\nano\meter}$, projected onto a 2D plane. b) Blue curve, spherical projection of the 2D simulation to 1D. Red dashed line, point of expanding density at $k=\SI{5}{\nano\meter}$.}
	\label{fig:cluster-generation}
\end{figure}
For the interpretation of the HeXe-cluster data that are discussed in the following chapter, 2D simulations were performed. These simulations model sphere-based electron densities of clusters and core--shell systems, and compute corresponding diffraction patterns. The simulations can be compared to the measured diffraction images or the reconstructed real-space images of HeXe-clusters. The results of the simulations support the analysis of experimentally measured data and the simulations furthermore allow the modeling of several thought-experiments, such as simulating various structures of the core--shell systems and comparing it to the experimental data. The 2D data of the simulations can optionally be reduced to 1D using a spherical integration (see Section \ref{sec:1d-proj-and-phase-reconstruction}) to be compared to the experimental data or analytical models. The clusters and core--shell systems are approximated using spheres, which is an acceptable estimation of the icosahedral cluster structure at the current resolution. The simulations are discussed in detail below.\\[1\baselineskip]
%
For the core--shell systems in this thesis, the simulated spheres should reflect the recorded HeXe-clusters (see Figure \ref{fig:HeXe-cluster-60}) and should therefore be adjustable in density, have various radii, be placed at varying locations, and should be allowed to exhibit a surface softening.
%we want to simulate a shell that consists of one large cluster with low electron density and therefore simulates a helium droplet, and the core comprises smaller dense spheres, which simulate the xenon doping.
%In the simulated, doped cluster, or more general the core--shell system, 
%The spheres can be arranged at different locations within the shell. Furthermore, the simulated spheres can expand to simulate the effect of a nanoplasma expansion. 
%These simulations start with an electron density that is formed of one or more spheres that are allowed to expand. The electron density is then Fourier transformed and squared to yield 2D diffraction images. 
Similar to Section \ref{sec:pump--probe-considerations} and Reference \cite{Gorkhover-2016-NatPho} can we express the electron density of a single sphere that has been projected onto a 2D plane using the formalism
\begin{align}
\rho\left(\vec{R}, k\right)&=\begin{cases}
2 \sqrt{r^{2}-\lvert \vec{R}\rvert^{2}} \cdot \rho_{0}& \text{, for $r-\frac{3 k}{2} \geq \lvert \vec{R}\rvert \geq 0$},\\
2 \sqrt{r^{2}-\lvert \vec{R}\rvert^{2}} \cdot \rho_{0} e^{\frac{(r-\frac{3k}{2})-\lvert \vec{R}\rvert}{k}}&\text{, for $r > \lvert \vec{R}\rvert - \frac{3k}{2}$},
\end{cases}
\label{eq:el-density-expanding-2d}
\intertext{with $\rho_{0}$ being the density, $r$ being the cluster radius, and $k$ an expansion parameter. In the 2D projection of the particle, the exponential surface softening was modified to fulfill}
\int_{0}^{\infty}&\rho\left(\lvert \vec{R}\rvert, k\right)d\vec{R} = r,\quad \text{if } 0<k<r .
\end{align}
This sphere can be positioned arbitrarily in a 2D array, which simulates the real space image, using $\vec{R}\rightarrow \vec{R}-\vec{R_{0}}$, with $\vec{R_{0}}$ being the center of mass of the sphere. From here, it is simple to construct the desired real space core-shell system. The electron densities of multiple spheres consisting of arbitrary radii and densities can be a added together onto the 2D array. In these simulations, the density $\rho_{0}$ was set to $\rho_{0, \text{helium}}=1$ for liquid helium and $\rho_{0,\text{xenon}}=\frac{3.640}{0.1412}\approx 25.8$ for xenon, with the numerator of the fraction for $\rho_{0,\text{xenon}}$ is the density of bulk xenon\index{Xenon!bulk density} in g/cm$^{3}$ and the denominator is the density for liquid helium\index{Helium!liquid density} in g/cm$^{3}$. Multiple spheres were arranged on a large array of \num{\sim 1500 x \sim 1500}, which is comparable to the combined pnCCD image array size. The array is then Fourier transformed\index{Fourier Transform} using \textsc{Matlab}'s\index{Matlab} function \textit{fft2}, the output is rearranged using the function \textit{fftshift}, and squared.\\[1\baselineskip]
\begin{figure}
	\centering
		\includegraphics[width=0.70\textwidth]{images/cluster-sphere-intact.png}
	\caption[Comparison of analytical derived scattering and numerical simulations.]{Comparison of analytical scattering from a sphere of radius $r=\SI{202}{\nano\meter}$ (black curve), Equation \eqref{eq:scattering from sphere}, and scattering of a sphere of radius $r=\SI{202}{\nano\meter}$ from 2D simulations projected onto 1D (green, dashed curve). The envelope of scattering intensity of a sphere (Porod's law) is $\propto \lvert \vec{Q}\rvert^{-4}$ (red curve). The analytical scattering and developed simulations agree well with each other.}
	\label{fig:cluster-sphere-intact-2D}
\end{figure}
As an example of a simulation, Figure \ref{fig:cluster-sphere-intact-2D} shows a comparison of the analytical derived scattering of a sphere (see Equation \eqref{eq:scattering from sphere}) with a radius of $r=\SI{202}{\nano\meter}$ (black, dashed line) and the scattering of the 2D simulations that has been reduced to 1D (green, solid line). The red curve is the envelope of the functions or Porod's law. The developed simulation agrees well with the analytical scattering, when $k=0$.
%
%
%
%\section{Time-of-flight data handling considerations at LCLS}\label{sec:acq-considerations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Adjustments to iTOF data
%% - Start value analysis
%% - light peak jitter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}
	%\centering
		%\includegraphics[width=0.7\textwidth]{images/Acqiris-waveform-readout.png}
	%\caption[Timing schematics of Acqiris digitizer.]{Schematics of the Acqiris digitizer timing system. The Acqiris reads out \num{40000} channels, whereby the initial 10 data points act as a ``rolling'' buffer in the Acqiris. If no trigger occurs within the initial channels, the buffer starts over. If the trigger occurs within the initial channels, the full trace is read out. This sometimes leads to channels within the rolling buffer being unused and discarded by the Acqiris. Another aspect is the finite time-interval between sampling points. In order to avoid losing data, the First data point is sometimes before the Time Origin depending on when the trigger occurred in the finite sampling. Schematic from \citep{Acqiris-manual},}
	%\label{fig:Acqiris-waveform-readout}
%\end{figure}
%A time-of-flight mass spectrometer typically produces an analog output, which is digitized, and stored as an array carrying the signal voltages and time stamps. At LCLS, usually an Acqiris digitizer (now called: Agilent digitizer) is used to read out the time-of-flight spectrometer. The in Section \ref{sec:TOF-spectrometer} discussed time-of-flight spectrometer has been read out with an Acqiris/Agilent U1065A, which is why it is discussed in more detail here. A schematic of the Acqiris timing system is shown in Figure \ref{fig:Acqiris-waveform-readout}. In general, the LCLS trigger system and the Acqiris are not synchronized and the Acqiris will continuously read out \num{40000} channels, disregarding any triggers. If the Acqiris sees no trigger after 10 sampling points, the read out of \num{40000} channels starts over. So, these initial 10 channels function as a circular buffer for the Acqiris. If, however, the Acqiris receives a trigger within the initial sampling points, it will continue to read out the remaining channels including the initial 10. Sampling points within the rolling buffer can therefore be before the trigger and are thus
%%For technical reasons, the Acqiris sampling rate and the Acqiris ``clock'' are generally not synchronized with the electronic trigger from LCLS-EVR that starts the readout process.
%%The electronic trigger can occur between the sampling point (1, 2, ..., or 10), as it is illustrated in the left panel of Figure \ref{fig:Acqiris-waveform-readout}. 
%%. When the Acqiris receives the trigger, it reads out \num{40000} samples including the 10 initial sampling points, so,
%removed from the trace by the Acqiris. But to avoid different trace lengths in the data analysis that vary from shot-to-shot, the LCLS DAQ group fills each array with zero entries until the trace is \num{40000} points long. This simplifies the data analysis and data handling of the array. The left panel of Figure \ref{fig:TOF-trace-light-peak} shows an histogram of the \textit{light peak} over \num{1000} events and the light peak occurs randomly distributed within a 10 channel window. Since the Acqiris and trigger system are not in synchronization, it is good practice to use the light peak position as starting point for the flight times and not the starting poin 
%TBD Additionally we should consider the case when the trigger comes in between two sampling points, where the time difference between the \textit{First data point} and the \textit{Time Origin} is within the sampling interval (see Figure \ref{fig:Acqiris-waveform-readout}). In this case, the Acqiris uses the first data point as first entry in the read out trace to avoid data loss. This first data point may have a negative time stamp attributed to it as the time origin occurs closer to the second data point. The right panel of Figure \ref{fig:Acqiris-waveform-readout} shows is a histogram of the time stamp from \num{5000} first data points. The time-stamp is evenly distributed, which is what one would expect when the electronic trigger ``randomly'' occurs in between sampling points.\\[1\baselineskip]
%\begin{figure}
	%\centering
		%\includegraphics[width=0.49\textwidth]{images/TOF-trace-light-peak.eps}
		%\includegraphics[width=0.49\textwidth]{images/firstDataPoint.eps}
	%\caption[TBD Using light peak to find absolute time zero in Acqiris traces.]{TBD Top plot, average TOF trace of xenon cluster upon irradiation with LCLS. Red curve, corrected run average to account for shifted light peak due to Acqiris sampling. Blue curve, uncorrected average. Bottom image, histogram of light peak channel position ranging between \num{+- 5} of channel 1514. The right image is a histogram of the the time-stamp from the First data point.}
	%\label{fig:TOF-trace-light-peak}
%\end{figure}
%Due to these considerations, the origin of time in a LCLS experiment is best defined by the light peak in a TOF trace. The time-of-flight spectrometer will detect photons scattered of the sample as the pulse is traversing through the system. This light peak is typically in the beginning of the TOF trace and for well scattering samples, such as xenon clusters, the light peak is a well-defined peak (see top panel of Figure \ref{fig:TOF-trace-light-peak}). 
%
%When \num{40000} channels are being read out, each channel corresponds to one sampling point at a sampling rate of 1 ns. The bottom panel of Figure \ref{fig:TOF-trace-light-peak} shows an analysis of the light peak position in the TOF trace. The light peak occurs within a \SI{\sim 10}{\nano\second} window and is evenly distributed around channel \num{1514}. We attribute this to the earlier mentioned ``rolling'' buffer. The top panel of Figure \ref{fig:TOF-trace-light-peak} shows an average of \num{1000} TOF trace (blue curve) and a TOF trace that has been corrected for the light peak occurring at different position (red curve). The data shows a very good agreement of both curves and indicates that at low time-resolution of a 1 ns sampling, the above considerations may be disregarded. 
%
%
%However, for high-resolution TOF spectroscopy the above considerations will become important. The time-of-flight analysis in this thesis accounts for the above considerations and additionally corrects for a common baseline.
%
%
%
\section{Data filtering}\label{sec:hitfinding}
%%%%%%%%%%%%
%- Discuss the hitfinding.\\
%- iTOF vs. pnCCD\\
%- vs. Actual dynamics visible in diffraction images
%%%%%%%%%%%%
\begin{figure}
	\centering
		\includegraphics[width=1.00\textwidth]{images/data-flow-chart.png}
	\caption{Schematic of data treatment and hit-finding procedures.}
	\label{fig:data-flow-chart}
\end{figure}
As described in Section \ref{sec:LCLS-computing}, LCLS produces large amounts of data with a variety of shot-to-shot intensity and therefore a data range. To analyze comparable events, the data have to be filtered, which is often referred to as \textit{hit-finding} \cite{Gorkhover-2012-PRL,Daurer-2016-JAC,Foucar-2016-JAC}. Typical for single particle imaging is to filter on events, where many photons have been captured by the detector. The difficulty for this work is that the sample dynamically evolves due to the pump-pulse. Figure \ref{fig:filter-size-intensity} showcases some of these dynamic processes in Xe-clusters and the data show that as the Xe-clusters undergo a nanoplasma expansion the scattered intensity decreases (details described later in Section \ref{sec:xenon-data}). This can be extrapolated to an extreme, where a cluster that has been intensely hit undergoes a nanoplasma expansion and therefore produces barely any signal on the front pnCCD. Fortunately, a cluster that has been intensely hit results in ion high-charge states and we can make full use of the coincident detection of diffraction image and time-of-flight trace. Figure \ref{fig:data-flow-chart} shows a flow chart of the data treatment. Initially, the data have been automatically filtered on ion high charge states using the time-of-flight signal. This resulted in several hundred to thousands events per pump--probe delay step. These hits were semi-automatically filtered on single cluster hits, which also allowed determining their size using the first maxima as described in Section \ref{sec:saxs}. This reduced the data significantly to, for example, 350 single Xe-cluster events over all delay steps. Some results of this procedure for Xe-clusters are shown in Figure \ref{fig:filter-size-intensity} and the data shows that Xe-cluster exhibit a linear average-Xe-cluster-radius increase of \SI{\sim 20}{\percent} over the course of the first \SI{800}{\femto\second} (see more in Section \ref{sec:xenon-data}).\\[1\baselineskip]
%In the left panel of Figure \ref{fig:filter-size-intensity}, the xenon pump--probe data has been automatically pre-filtered on xenon ion high-charge states, leaving several thousand events that were then semi-automatically reduced to over 350 single-hit diffraction images. This semi-automatic process determines, whether it was a single hit and the size of a cluster.
%The size determinations have been performed using the first maxima as described (see Section \ref{sec:saxs}). The plotted events in Figure \ref{fig:filter-size-intensity} indicate a linear average-Xe-cluster-radius increase of \SI{\sim 20}{\percent} over the course of the first 800 fs (see more in Section \ref{sec:xenon-data}).
To perform phase retrieval and to solve the inverse problem, bright hits containing many photons are required. Therefore, another filter has been implemented that automatically filters for events with much scattered intensity. The \num{\sim 30} remaining diffraction images of single Xe-cluster events per delay step have then been semi-automatically displayed in a 1D representation and compared to the scattering of a sphere. Now, events containing dynamics became obvious and the brightest hits that show signs of X-ray radiation damage have been selected manually for phase-retrieval. The phase-retrieval is an intractable process that not always resulted in physical recovery of the object, which lead to further exclusion of events. The He- and HeXe-cluster data have been treated in the same way as the above discussed example of Xe-clusters.
%%%%%%%%%%%%%%%%%% Use me
%A large scale analysis of size, scattered intensity and shape is performed on single-shot diffraction patterns of xenon clusters to investigate the nanoplasma transition. The analysis starts by selecting useful hits from an experimental run using the methods described in Section \ref{sec:hitfinding}. A typical run length is 20 min and results in a total of \num{\sim 36000} images. These events are automatically reduced to \num{\sim 1000} events by filtering on high-charge states of Xe-ions. Then, a semi-automatic routine reduces the data to a subset of 30 to 60 single-shot diffraction patterns per run. This breakdown allows the estimation that \SIrange{0.08}{0.16}{\percent} of all imaged xenon clusters had good parameters for analysis per run. Multiple runs of data were taken as the pump--probe delay $\Delta t$ was varied.\\[1\baselineskip]
%%%%%%%%%%%%%%%%%%
%These hits undergo a phase retrieval to reveal their electron density. To clarify, single He- and Xe-cluster hits show X-ray induced dynamics, when the 1d reduction of the intensity profile differs from the scattering of an intact sphere, i.e., $\tfrac{I}{F_{\text{intact}}^{2}} \ll 1$. The case of X-ray induced dyanmics in HeXe-clusters is discussed in more detail in Section \ref{sec:helium-xenon-data}.
%For the present work, a useful event is the interaction of X-ray pump--X-ray probe pulse sequence with a single cluster system. On the one hand, clusters produce the most intense signal on pnCCD and TOF detectors when they are in the center of the intensity profile of the LCLS beam \citep{Gorkhover-2012-PRL}. On the other hand, as the time delay, $\Delta t$, of the X-ray pump--X-ray probe is increased, the nanoplasma expansion leads to a decrease in signal on the pnCCD (see Figure \ref{fig:filter-size-intensity}). 
%
%
%